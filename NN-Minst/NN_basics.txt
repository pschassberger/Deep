What is a NN? - https://www.youtube.com/watch?v=aircAruvnKk

NN components:
    - Input layer
    - Hidden layer
    - Output layer, y_hat
    - Weights and biases. W and b
    - Activation function, sigma

Training the two layer NN:
    - the output y_hat is defined as: y_hat = sigma(W2 * sigma * (W1x + b1) + b2)
"Naturally, the right values for the weights and biases determines the strength of the predictions. 
The process of fine-tuning the weights and biases from the input data is known as training the Neural Network.
Each iteration of the training process consists of the following steps:
    - Calculating the predicted output ŷ, known as feedforward
    - Updating the weights and biases, known as backpropagation"[1]

Loss Function:
    - Used to determine our accuracy
    - will use the sum-of-squares error as our loss function 

"Our goal in training is to find the best set of weights and biases that minimizes the loss function.
Backpropagation
Now that we’ve measured the error of our prediction (loss), we need to find 
a way to propagate the error back, and to update our weights and biases.
In order to know the appropriate amount to adjust the weights and biases by, 
we need to know the derivative of the loss function with respect to the weights and biases.

If we have the derivative, we can simply update the weights and biases by increasing/reducing with 
it(refer to the diagram above). This is known as gradient descent."[1]
